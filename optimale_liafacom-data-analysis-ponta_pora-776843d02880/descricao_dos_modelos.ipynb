{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descrição dos Modelos utlizados nas análises\n",
    "\n",
    "Na fase de análise dos dados de medição foram empregados 3 modelos distintos, sendo eles: LSTM (Long-Short Term Memory)[https://keras.io/getting-started/sequential-model-guide/], KNN(K-nearest Neighbors)[http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor] e SARIMAX(Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors model)[http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html]. Os dados utilizados até então totalizam em torno de 4 meses de medições, sendo a analise atual obtida a partir de médias de 30min. Nós dividimos as análise em duas abordagens centrais. A primeira consiste de um forecasting de tamanho n > 1 (e.g. 24) no qual o resultado da predição p é entrada para o cálculo da predição p+1, p < n. Na segunda abordagem denominada janela deslizante, para efetuar a análise da performance do nosso modelo, vamos efetuando a predição de um valor a frente, calculamos o erro dado que temos o valor target e vamos \"andando\" com um \"janela\" sobre o conjunto de teste. O erro em ambas abordagens é o erro quadrado, que é acumulado e apresentado no final da análise. Na abordagem por realimentação o dataset é da forma [X,y], onde X[i] é da forma [24 valores anteriores, próximo valor]. Já na abordagem por janelas deslizantes, o dataset contém em X, valores de 48 pontos anteriores e y o próximo valor, ou seja, X[i] é da forma  [48 valores anteriores, próximo valor]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametros dos modelos\n",
    "Para ambas as abordagens 80% dos dataset é utilizado como treino e 20% para teste. No entanto, na abordagem por janelas deslizantes os k valores finais do conjunto de treino são usados no conjunto de teste. Os parâmetros foram estudados previamente para a escolha dos melhores valores para cada modelo, porém um estudo mais aprofundado sobre os parâmetros específicos do modelo ARIMA e como obtê-los de maneira automatizada é válido.\n",
    "### Metodologia retroaliamentada\n",
    "**KNN**  : \n",
    "    1. n_neighbors = 1, \n",
    "    2. weights='uniform', \n",
    "    3. algorithm='auto', \n",
    "    4. leaf_size=30, \n",
    "    5. p=2, \n",
    "    6. metric='minkowski'\n",
    "    \n",
    "**LSTM** :\n",
    "    1. Sequential()\n",
    "    2. LSTM(units=10, input_dim=24)\n",
    "    3. Dense(units=1) # essa camada efetua output = activation(dot(input, kernel) + bias) \n",
    "    4. optimizer='adam'\n",
    "    5. loss='mean_squared_error'\n",
    "    6. nb_epoch=49\n",
    "    7. batch_size=128\n",
    "    \n",
    "**SARIMAX**:\n",
    "    1. order=(0, 1, 1)\n",
    "    2. seasonal_order=(0,1,1,48), \n",
    "    3. trend='n',\n",
    "    4. mle_regression=True, \n",
    "    5. enforce_stationarity=True, \n",
    "    6. enforce_invertibility=True\n",
    "\n",
    "### Metodologia janelas deslizantes\n",
    "**KNN**  : \n",
    "    1. n_neighbors = 1, \n",
    "    2. weights='uniform', \n",
    "    3. algorithm='auto',\n",
    "    4. leaf_size=30,\n",
    "    5. p=2, \n",
    "    6. metric='minkowski'\n",
    "    \n",
    "**LSTM** :\n",
    "    1. Sequential()\n",
    "    2. LSTM(units=10, input_dim=48)\n",
    "    3. Dense(units=1) \n",
    "    4. optimizer='adam'\n",
    "    5. loss='mean_squared_error'\n",
    "    6. nb_epoch=49\n",
    "    7. batch_size=128\n",
    "    \n",
    "**SARIMAX**:\n",
    "    1. order=(0, 1, 1)\n",
    "    2. seasonal_order=(0,1,1,48), \n",
    "    3. trend='n',\n",
    "    4. mle_regression=True, \n",
    "    5. enforce_stationarity=True, \n",
    "    6. enforce_invertibility=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na abordagem por janelas deslizantes, o erro é calculado com relação a **todo o conjunto de teste**, enquanto que na abordagem por realimentação efetua-se o forecasting de tamanho 48 (24h) e calcula-se o erro com relação **aos primeiros 48 pontos do conjunto de teste**.\n",
    "**NOTE**: LSTMs são sensiveis a escala do dado de entrada, especificamente quando a função de ativação utilizada é a sigmoid(default). Portanto, seguindo uma boa prática, efetuamos uma transformação de escala para valores entre (0,1), usando a função sklearn.preprocessing.MinMaxScaler. Após o treinameto da rede os valores são reajustados a escala inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
